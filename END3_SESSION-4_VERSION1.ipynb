{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA P2S3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpratiek/END_NLP/blob/main/END3_SESSION-4_VERSION1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cb482b-6b2e-4f95-83c4-fefa33c5656b"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TCzEQf4KFIG",
        "outputId": "fb617057-d9cb-414c-db6b-cbcfe257a644"
      },
      "source": [
        "chars"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[';',\n",
              " '–',\n",
              " 'L',\n",
              " 'a',\n",
              " 't',\n",
              " '1',\n",
              " 'U',\n",
              " 'i',\n",
              " 'e',\n",
              " 'u',\n",
              " 'W',\n",
              " '9',\n",
              " 'c',\n",
              " 'B',\n",
              " 'M',\n",
              " 'y',\n",
              " 's',\n",
              " '8',\n",
              " 'f',\n",
              " 'S',\n",
              " 'T',\n",
              " '2',\n",
              " 'x',\n",
              " ')',\n",
              " 'D',\n",
              " '4',\n",
              " '5',\n",
              " 'o',\n",
              " 'P',\n",
              " '6',\n",
              " 'g',\n",
              " 'd',\n",
              " ' ',\n",
              " '(',\n",
              " 'R',\n",
              " 'm',\n",
              " 'n',\n",
              " '\\n',\n",
              " '?',\n",
              " 'E',\n",
              " 'h',\n",
              " 'w',\n",
              " '’',\n",
              " 'K',\n",
              " 'b',\n",
              " '.',\n",
              " 'I',\n",
              " 'Y',\n",
              " '0',\n",
              " 'q',\n",
              " 'J',\n",
              " 'j',\n",
              " '�',\n",
              " 'z',\n",
              " '“',\n",
              " 'p',\n",
              " 'V',\n",
              " 'H',\n",
              " '\"',\n",
              " 'r',\n",
              " '7',\n",
              " 'F',\n",
              " 'O',\n",
              " 'G',\n",
              " 'v',\n",
              " ',',\n",
              " 'k',\n",
              " '3',\n",
              " '-',\n",
              " \"'\",\n",
              " ':',\n",
              " 'A',\n",
              " 'N',\n",
              " 'l',\n",
              " 'C']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "# Hidden_Layer_size = 10 #size of the hidden layer\n",
        "# Time_steps = 10 # Number of time steps (length of the sequence) used for training\n",
        "\n",
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return sigmoid(y) * (1-sigmoid(y))\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.sinh(x) / np.cosh(x) \n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - (tanh(y))**2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClmBEQJ02ID3",
        "outputId": "e45e23f8-3107-43bb-8c6a-eb693b857be2"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QngkCGg_2Mrp",
        "outputId": "30478b47-47bc-4467-aea8-cd24bd1eedda"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2350037122015945"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlYasQTJ26Jq",
        "outputId": "defad8a4-509f-473e-9493-9f1f8bd0a623"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0))) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23077102729268234"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhCm-_2s26VY",
        "outputId": "0f0d4293-9d1a-48bb-db18-b025cd0f2f97"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0)))) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9485799654066528"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size\n",
        "size_b = z_size\n",
        "size_c = X_size\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgQIUAUTEEwc"
      },
      "source": [
        "**ROUGH WORK**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmtT5JD73zZF"
      },
      "source": [
        "# z = np.random.randn(85, 1)\n",
        "# C_prev = np.random.randn(10, 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XBIKhZO3foT"
      },
      "source": [
        "# f = sigmoid(parameters.W_f.v @ z + parameters.b_f.v)\n",
        "# i = sigmoid(parameters.W_i.v @ z + parameters.b_i.v)\n",
        "# C_bar = tanh(parameters.W_C.v @ z + parameters.b_C.v)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFJoBLNcDmnu"
      },
      "source": [
        "# f,i,C_bar"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdZMsAptDwer"
      },
      "source": [
        "# C = f * C_prev + i*C_bar\n",
        "# o = sigmoid(parameters.W_o.v @ z + parameters.b_o.v)\n",
        "# h = o * tanh(C)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycfIR06JENSc"
      },
      "source": [
        "# C,o,h"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGLFpLlDEg2a"
      },
      "source": [
        "# parameters.W_v.v @ h"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlIU_QYiEUen"
      },
      "source": [
        "# v = parameters.W_v.v @ h + parameters.b_v.v\n",
        "# y = np.exp(v) / np.sum(np.exp(v))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS2iVJpUFfdN"
      },
      "source": [
        "# y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(parameters.W_f.v @ z + parameters.b_f.v)\n",
        "    i = sigmoid(parameters.W_i.v @ z + parameters.b_i.v)\n",
        "    C_bar = tanh(parameters.W_C.v @ z + parameters.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i*C_bar\n",
        "    o = sigmoid(parameters.W_o.v @ z + parameters.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = parameters.W_v.v @ h + parameters.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-UIgC3oGeig",
        "outputId": "8f9296f0-73e4-4e0b-cca4-2b6bad3ea680"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(175, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhzgEgCMGg81",
        "outputId": "dfa3b15a-e633-4b29-fa6d-9c99e11a0c16"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ICPqQ7GjEk",
        "outputId": "eb6abc30-1056-447c-fa2b-7fb447b8c34e"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_nHiqxoGYA1",
        "outputId": "7170cd02-357d-48b0-e984-759da57339e4"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "15e6d763-8b93-47f0-f0e9-487e2890b223"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            " s Mhkon''d  rspasyeere l orp avavfie ntient ilussiiM s, s setlls auasryuebor nr  ouscereleeoif heh d ve)r ruDrgeurerAlass, rrie e frgtse ereeeye utusr t s ingvfecaugorp hsedh kot iioin0 std umspoe  ia \n",
            "----\n",
            "iter 49900, loss 112.581073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKsXE0sjFVHO"
      },
      "source": [
        "112.581073"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}